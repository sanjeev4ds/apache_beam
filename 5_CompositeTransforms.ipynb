{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaTIp8Q8F7zT",
        "outputId": "339b7061-60cc-4dc0-e8f4-9dce33d3fd78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires grpcio>=1.71.0, but you have grpcio 1.65.5 which is incompatible.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!{'pip install --quiet apache_beam'}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "class PairPerson(beam.DoFn):\n",
        "  def process(self, element, dept):\n",
        "    return [(dept+','+element[1], 1)]\n",
        "\n",
        "def filter_on_count(element):\n",
        "  name, count = element\n",
        "  if count> 30:\n",
        "    return element\n",
        "\n",
        "def format_output(element):\n",
        "  name, count = element\n",
        "  return ','.join((name, str(count), 'Regular employee'))\n",
        "\n",
        "class MyTransform(beam.PTransform):\n",
        "\n",
        "  def expand(self, input_collection):\n",
        "    a = (\n",
        "        input_collection\n",
        "        | 'Group and sum' >> beam.CombinePerKey(sum)\n",
        "        | 'count filter' >> beam.Filter(filter_on_count)\n",
        "        | 'Regular accounts employee'>> beam.Map(format_output)\n",
        "    )\n",
        "    return a\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "  input_collection = (\n",
        "      p\n",
        "      | 'read from text file' >> beam.io.ReadFromText('drive/MyDrive/APACHE_BEAM/datasets/dept_data.txt')\n",
        "      | 'split_row' >> beam.Map(lambda record: record.split(\",\"))\n",
        "  )\n",
        "\n",
        "  accounts_count = (\n",
        "      input_collection\n",
        "      | 'filter Accounts dept persons' >> beam.Filter(lambda record: record[3]==\"Accounts\")\n",
        "      | 'pair account with 1' >> beam.ParDo(PairPerson(), 'Accounts')\n",
        "      | 'composite account'>> MyTransform() # calling composite transform class here\n",
        "  )\n",
        "\n",
        "  hr_count = (\n",
        "      input_collection\n",
        "      | 'filter hr dept persons' >> beam.Filter(lambda record: record[3]==\"HR\")\n",
        "      | 'pair hr with 1' >> beam.ParDo(PairPerson(), 'HR')\n",
        "      | 'composite hr'>> MyTransform() # calling composite transform class here\n",
        "  )\n",
        "\n",
        "  combine_count = (\n",
        "      (accounts_count, hr_count)\n",
        "      | beam.Flatten()\n",
        "      | beam.Map(print)\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQOY3rTZGGym",
        "outputId": "11e9903c-9b38-4f61-931c-102c4b33e723"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accounts,Marco,31,Regular employee\n",
            "Accounts,Rebekah,31,Regular employee\n",
            "Accounts,Itoe,31,Regular employee\n",
            "Accounts,Edouard,31,Regular employee\n",
            "Accounts,Kyle,62,Regular employee\n",
            "Accounts,Kumiko,31,Regular employee\n",
            "Accounts,Gaston,31,Regular employee\n",
            "HR,Beryl,62,Regular employee\n",
            "HR,Olga,31,Regular employee\n",
            "HR,Leslie,31,Regular employee\n",
            "HR,Mindy,31,Regular employee\n",
            "HR,Vicky,31,Regular employee\n",
            "HR,Richard,31,Regular employee\n",
            "HR,Kirk,31,Regular employee\n",
            "HR,Kaori,31,Regular employee\n",
            "HR,Oscar,31,Regular employee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mg1eV4sPHJmK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}